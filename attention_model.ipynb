{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQLFotRZPMaG"
   },
   "source": [
    "Let’s implement a basic attention mechanism in Python to reinforce the concepts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QonBRCaJPMaH",
    "outputId": "a95af3cd-638c-4ff1-b026-b814d5d427ff",
    "ExecuteTime": {
     "end_time": "2025-10-30T07:27:58.491918Z",
     "start_time": "2025-10-30T07:27:58.354069Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define query, keys, and values as vectors\n",
    "query = np.array([1, 0, 1])  # Represents \"love\"\n",
    "keys = np.array([[1, 0, 1],  # Represents \"pizza\"\n",
    "                 [0, 1, 0],  # Represents \"but\"\n",
    "                 [1, 0, -1]])  # Represents \"olives\"\n",
    "values = np.array([[5], [0], [-3]])  # Sentiment scores for \"pizza,\" \"but,\" \"olives\"\n",
    "\n",
    "# Calculate attention scores (dot product of query and keys)\n",
    "scores = np.dot(keys, query)\n",
    "\n",
    "# Apply softmax to get weights\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "weights = softmax(scores)\n",
    "\n",
    "# Weighted sum of values\n",
    "attention_output = np.dot(weights, values)\n",
    "\n",
    "print(\"Attention Scores:\", scores)\n",
    "print(\"Attention Weights:\", weights)\n",
    "print(\"Attention Output:\", attention_output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores: [2 0 0]\n",
      "Attention Weights: [0.78698604 0.10650698 0.10650698]\n",
      "Attention Output: [3.61540927]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy4GBnqgPMaJ"
   },
   "source": [
    "To improve stability for high-dimensional vectors, we scale the dot product by dividing by the square root of the key dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aokQ07hPMaJ",
    "outputId": "876a0a7f-b6e6-4b37-8b21-cbb159f83905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Attention Scores: [1.15470054 0.         0.        ]\n",
      "Attention Weights: [0.61338261 0.19330869 0.19330869]\n",
      "Attention Output: [2.48698697]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define query, keys, values, and scaling factor\n",
    "query = np.array([1, 0, 1])\n",
    "keys = np.array([[1, 0, 1],\n",
    "                 [0, 1, 0],\n",
    "                 [1, 0, -1]])\n",
    "values = np.array([[5], [0], [-3]])\n",
    "scale = np.sqrt(query.shape[0])  # d_k = dimensionality of the query\n",
    "\n",
    "# Calculate scaled attention scores\n",
    "scores = np.dot(keys, query) / scale\n",
    "\n",
    "# Apply softmax to get weights\n",
    "weights = softmax(scores)\n",
    "\n",
    "# Weighted sum of values\n",
    "attention_output = np.dot(weights, values)\n",
    "\n",
    "print(\"Scaled Attention Scores:\", scores)\n",
    "print(\"Attention Weights:\", weights)\n",
    "print(\"Attention Output:\", attention_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b04tlJcPMaJ"
   },
   "source": [
    "## Self Attention\n",
    "Let’s implement a simple self-attention mechanism for a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHtUf4V3PMaJ",
    "outputId": "c57a7333-a2de-48c2-dbb6-a711c68e6df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights:\n",
      "[[0.13996839 0.23453985 0.24576871 0.15175171 0.22797133]\n",
      " [0.01847211 0.30437435 0.39016773 0.02861227 0.25837354]\n",
      " [0.01474143 0.30522766 0.39994043 0.02367127 0.25641921]\n",
      " [0.10588597 0.2546468  0.27557477 0.12146871 0.24242375]\n",
      " [0.02037275 0.30283715 0.38578421 0.03107175 0.25993415]]\n",
      "Attention Output:\n",
      "[[1.04688219 1.35331457 0.98510099]\n",
      " [1.30097982 1.68605596 1.22570457]\n",
      " [1.31055465 1.69852508 1.23472785]\n",
      " [1.11290351 1.43982809 1.04766729]\n",
      " [1.29621874 1.67979842 1.22119359]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define structured sentence embeddings (each row represents a word)\n",
    "# The embeddings represent semantic roles:\n",
    "# \"The\" (determiner), \"cat\" (subject noun), \"sat\" (verb), \"on\" (preposition), \"mat\" (object noun)\n",
    "sentence_embeddings = np.array([\n",
    "    [0.1, 0.1, 0.2],  # \"The\"  (low influence determiner)\n",
    "    [0.9, 0.8, 0.7],  # \"cat\"  (subject noun, strong influence)\n",
    "    [0.8, 0.9, 0.8],  # \"sat\"  (verb, central word, strong influence)\n",
    "    [0.2, 0.2, 0.3],  # \"on\"   (preposition, weak influence but linked to \"mat\")\n",
    "    [0.7, 0.6, 0.9]   # \"mat\"  (object noun, linked to \"on\" and \"sat\", but not \"the\")\n",
    "])\n",
    "\n",
    "# Define structured weight matrices for Query (Q), Key (K), and Value (V)\n",
    "# These weights are manually structured to enhance word relationships\n",
    "\n",
    "# Query weight matrix (W_q) (3x3)\n",
    "# Controls how much influence each word has when \"asking for context\"\n",
    "W_q = np.array([\n",
    "    [0.6, 0.2, 0.1],  # Slight attention to structure words\n",
    "    [0.8, 0.7, 0.6],  # \"cat\" has high query influence\n",
    "    [0.7, 0.9, 0.8]   # \"sat\" is the central querying word\n",
    "])\n",
    "\n",
    "# Key weight matrix (W_k) (3x3)\n",
    "# Controls how words \"store\" information for queries to access\n",
    "W_k = np.array([\n",
    "    [0.6, 0.3, 0.2],  # \"The\" contributes weakly to keys\n",
    "    [0.8, 0.7, 0.5],  # \"cat\" stores important information\n",
    "    [0.7, 0.9, 0.6]   # \"sat\" stores strong reference points\n",
    "])\n",
    "\n",
    "# Value weight matrix (W_v) (3x3)\n",
    "# Controls how much information each word contributes to the final representation\n",
    "W_v = np.array([\n",
    "    [0.2, 0.5, 0.3],  # \"The\" contributes little meaning\n",
    "    [0.7, 0.8, 0.6],  # \"Cat\" contributes strongly\n",
    "    [0.8, 0.9, 0.7]   # \"Sat\" contributes highly\n",
    "])\n",
    "\n",
    "# Compute Queries (Q), Keys (K), and Values (V) for each word\n",
    "Q = sentence_embeddings @ W_q  # Transform embeddings into Queries\n",
    "K = sentence_embeddings @ W_k  # Transform embeddings into Keys\n",
    "V = sentence_embeddings @ W_v  # Transform embeddings into Values\n",
    "\n",
    "# Compute attention scores using scaled dot-product attention\n",
    "scores = Q @ K.T  # Compute raw attention scores (similarity between Q and K)\n",
    "\n",
    "# Scale scores to stabilize training (common practice in attention models)\n",
    "d_k = K.shape[1]  # Dimension of keys\n",
    "scores /= np.sqrt(d_k)  # Scaling factor\n",
    "\n",
    "# Apply softmax to obtain normalized attention weights\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtract max value for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)  # Normalize rows\n",
    "\n",
    "weights = softmax(scores)  # Compute final attention weights\n",
    "\n",
    "# Compute weighted sum of values to get attention output\n",
    "attention_output = weights @ V  # Weighted combination of V based on attention\n",
    "\n",
    "# Print the attention matrix (how words attend to each other)\n",
    "print(\"Attention Weights:\")\n",
    "print(weights)\n",
    "\n",
    "# Print the final contextualized word representations\n",
    "print(\"Attention Output:\")\n",
    "print(attention_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwD5IpOnPMaK"
   },
   "source": [
    "## Multi-Head Attention\n",
    "Let’s implement a simple version of multi-head attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Pg9DIMLPMaL",
    "outputId": "d2e01a79-0284-40d8-e7ca-e3395434935e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head 1:\n",
      "Attention Weights:\n",
      "[[0.19687765 0.20256664 0.20184662 0.19757994 0.20112916]\n",
      " [0.1727621  0.2232503  0.21620917 0.17838832 0.20939011]\n",
      " [0.17568776 0.22065491 0.21445791 0.18076445 0.20843496]\n",
      " [0.193778   0.20513864 0.20368291 0.19516293 0.20223752]\n",
      " [0.17863977 0.21806136 0.21269322 0.18314844 0.20745723]]\n",
      "Attention Output:\n",
      "[[0.39804471]\n",
      " [0.41973964]\n",
      " [0.41707689]\n",
      " [0.40080164]\n",
      " [0.41439898]]\n",
      "\n",
      "\n",
      "Head 2:\n",
      "Attention Weights:\n",
      "[[0.19921608 0.20052285 0.20071023 0.19940224 0.20014861]\n",
      " [0.19376598 0.20417066 0.20570196 0.19521925 0.20114215]\n",
      " [0.19299284 0.20468993 0.20641784 0.19462201 0.20127738]\n",
      " [0.19843347 0.20104528 0.20142119 0.1988045  0.20029556]\n",
      " [0.19531638 0.20313068 0.20427224 0.19641403 0.20086666]]\n",
      "Attention Output:\n",
      "[[0.08126514]\n",
      " [0.08229866]\n",
      " [0.08244593]\n",
      " [0.08141305]\n",
      " [0.08200382]]\n",
      "\n",
      "\n",
      "Final Multi-Head Attention Output:\n",
      "[[0.39804471 0.08126514]\n",
      " [0.41973964 0.08229866]\n",
      " [0.41707689 0.08244593]\n",
      " [0.40080164 0.08141305]\n",
      " [0.41439898 0.08200382]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define sentence embeddings for each word in \"The cat sat on the mat\"\n",
    "# Each word is represented as a 3-dimensional vector (for simplicity)\n",
    "sentence_embeddings = np.array([\n",
    "    [0.1, 0.1, 0.2],  # \"The\"  (low influence)\n",
    "    [0.9, 0.8, 0.7],  # \"cat\"  (high influence)\n",
    "    [0.8, 0.9, 0.8],  # \"sat\"  (central word)\n",
    "    [0.2, 0.2, 0.3],  # \"on\"   (context word)\n",
    "    [0.7, 0.6, 0.9]   # \"mat\"  (linked to \"sat\" and \"on\")\n",
    "])\n",
    "\n",
    "# Multi-head attention will have two heads for this example\n",
    "num_heads = 2\n",
    "head_dim = sentence_embeddings.shape[1] // num_heads  # Dimension per head\n",
    "\n",
    "# Function to create weight matrices for each head\n",
    "# We'll create separate W_q, W_k, W_v for each head\n",
    "np.random.seed(42)  # Seed for reproducibility\n",
    "def generate_weights(num_heads, head_dim):\n",
    "    return [\n",
    "        (np.random.rand(head_dim, head_dim),  # W_q for this head\n",
    "         np.random.rand(head_dim, head_dim),  # W_k for this head\n",
    "         np.random.rand(head_dim, head_dim))  # W_v for this head\n",
    "        for _ in range(num_heads)\n",
    "    ]\n",
    "\n",
    "# Generate separate weight matrices for each head\n",
    "multi_head_weights = generate_weights(num_heads, head_dim)\n",
    "\n",
    "# Define softmax function for numerical stability\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Perform multi-head attention\n",
    "all_attention_outputs = []\n",
    "for head_index, (W_q, W_k, W_v) in enumerate(multi_head_weights):\n",
    "    # Slice the sentence embeddings for this head\n",
    "    # Each head will process a different projection of the embeddings\n",
    "    head_embeddings = sentence_embeddings[:, head_index * head_dim : (head_index + 1) * head_dim]\n",
    "\n",
    "    # Compute Queries (Q), Keys (K), and Values (V) for this head\n",
    "    Q = head_embeddings @ W_q  # Transform embeddings into Queries\n",
    "    K = head_embeddings @ W_k  # Transform embeddings into Keys\n",
    "    V = head_embeddings @ W_v  # Transform embeddings into Values\n",
    "\n",
    "    # Compute attention scores using scaled dot-product attention\n",
    "    scores = Q @ K.T  # Compute raw attention scores (similarity between Q and K)\n",
    "    d_k = K.shape[1]  # Dimension of keys\n",
    "    scores /= np.sqrt(d_k)  # Scale scores for numerical stability\n",
    "\n",
    "    # Apply softmax to obtain normalized attention weights\n",
    "    attention_weights = softmax(scores)\n",
    "\n",
    "    # Compute weighted sum of values to get the attention output for this head\n",
    "    attention_output = attention_weights @ V\n",
    "\n",
    "    # Store the attention output for this head\n",
    "    all_attention_outputs.append(attention_output)\n",
    "\n",
    "    # Print detailed information for this head\n",
    "    print(f\"Head {head_index + 1}:\")\n",
    "    print(\"Attention Weights:\")\n",
    "    print(attention_weights)\n",
    "    print(\"Attention Output:\")\n",
    "    print(attention_output)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Concatenate the outputs from all heads to form the final multi-head attention output\n",
    "final_attention_output = np.concatenate(all_attention_outputs, axis=1)\n",
    "\n",
    "# Print the final multi-head attention output\n",
    "print(\"Final Multi-Head Attention Output:\")\n",
    "print(final_attention_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eOFhX1zPMaL"
   },
   "source": [
    "## Encoder-Only Models\n",
    "Let's introduce the Bidirectional encoder representations from transformers (BERT) to create sentence embeddings.  The BERT model represents words with a 768-dimensional vector that captures the contextual meaning of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VXEYv9DcPMaM",
    "outputId": "cee4bc4d-23cd-49d8-83a9-89c768015df6",
    "colab": {
     "referenced_widgets": [
      "e92bb75990f14336989d1267286b47a3"
     ]
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T19:44:22.726493Z",
     "start_time": "2025-10-30T19:43:25.203828Z"
    }
   },
   "source": [
    "%pip install transformers torch\n",
    "\n",
    "# Import required libraries\n",
    "from transformers import BertTokenizer, BertModel  # Pretrained BERT tokenizer and model\n",
    "import torch  # For tensor manipulation (similar to NumPy)\n",
    "\n",
    "# Load a pretrained BERT model and tokenizer\n",
    "# BERT base uncased: lowercase version of the model trained on English text\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in evaluation mode (not training)\n",
    "model.eval()\n",
    "\n",
    "# Step 1: Define a sentence for embedding\n",
    "sentence = \"The cat sat on the mat.\"\n",
    "\n",
    "# Step 2: Tokenize the sentence\n",
    "# Tokenization converts the sentence into tokens that BERT understands.\n",
    "# BERT uses WordPiece tokenization, which splits words into subwords if necessary.\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")  # \"pt\" indicates PyTorch tensors\n",
    "print(\"Tokenized Input IDs:\", inputs['input_ids'])\n",
    "print(\"Attention Mask:\", inputs['attention_mask'])\n",
    "\n",
    "# Explanation of Tokenized Output:\n",
    "# input_ids: Each word/subword is converted to an integer representing its vocabulary index.\n",
    "# attention_mask: A binary mask indicating which tokens are real (1) and which are padding (0).\n",
    "\n",
    "# Step 3: Pass the tokenized inputs through the BERT model\n",
    "with torch.no_grad():  # Disable gradient calculation (not needed for inference)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Step 4: Extract the hidden states from BERT's output\n",
    "# BERT returns two outputs: the last hidden state and the pooled output.\n",
    "# The last hidden state contains embeddings for each token in the input sentence.\n",
    "last_hidden_state = outputs.last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "# Step 5: Average the token embeddings to create a sentence embedding\n",
    "# This is a simple way to get a fixed-size vector representing the entire sentence.\n",
    "sentence_embedding = last_hidden_state.mean(dim=1)  # Average across the sequence length dimension\n",
    "\n",
    "# Print the sentence embedding\n",
    "print(\"Sentence Embedding Shape:\", sentence_embedding.shape)\n",
    "print(\"Sentence Embedding Vector:\", sentence_embedding)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin/ponysay/balloon.py:46: SyntaxWarning: invalid escape sequence '\\-'\r\n",
      "/opt/homebrew/bin/ponysay/balloon.py:46: SyntaxWarning: invalid escape sequence '\\-'\r\n",
      "\u001B[0m\u001B[0m\u001B[38;5;48m \u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;48m_\u001B[39m\u001B[38;5;84m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;83m_\u001B[39m\u001B[38;5;119m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;118m_\u001B[39m\u001B[38;5;154m_\u001B[39m\u001B[38;5;154m_\u001B[39m\u001B[38;5;154m_\u001B[39m\u001B[38;5;154m_\u001B[39m\u001B[38;5;154m_\u001B[39m\u001B[38;5;154m \u001B[39m\u001B[0m\u001B[38;5;154m\u001B[39m\u001B[38;5;154m\u001B[39m\r\n",
      "\u001B[0m\u001B[38;5;48m<\u001B[39m\u001B[38;5;48m \u001B[39m\u001B[38;5;48mG\u001B[39m\u001B[38;5;48mo\u001B[39m\u001B[38;5;84mo\u001B[39m\u001B[38;5;83md\u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83mm\u001B[39m\u001B[38;5;83mo\u001B[39m\u001B[38;5;83mr\u001B[39m\u001B[38;5;83mn\u001B[39m\u001B[38;5;83mi\u001B[39m\u001B[38;5;83mn\u001B[39m\u001B[38;5;83mg\u001B[39m\u001B[38;5;83m,\u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;119ms\u001B[39m\u001B[38;5;118mu\u001B[39m\u001B[38;5;118mn\u001B[39m\u001B[38;5;118ms\u001B[39m\u001B[38;5;118mh\u001B[39m\u001B[38;5;118mi\u001B[39m\u001B[38;5;118mn\u001B[39m\u001B[38;5;118me\u001B[39m\u001B[38;5;118m!\u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m—\u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154mN\u001B[39m\u001B[38;5;154mi\u001B[39m\u001B[38;5;154mt\u001B[39m\u001B[38;5;154mi\u001B[39m\u001B[38;5;154mn\u001B[39m\u001B[0m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m>\u001B[39m\u001B[0m\u001B[38;5;154m\u001B[39m\u001B[38;5;148m\u001B[39m\r\n",
      "\u001B[0m\u001B[38;5;48m \u001B[39m\u001B[38;5;84m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;83m-\u001B[39m\u001B[38;5;119m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;118m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;154m-\u001B[39m\u001B[38;5;148m-\u001B[39m\u001B[38;5;184m \u001B[39m\u001B[0m\u001B[00m\u001B[38;5;184m\u001B[39m\u001B[38;5;184m\u001B[39m\r\n",
      "\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;119m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[0m\u001B[38;5;154m\\\u001B[39m\u001B[0m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[00m\u001B[38;5;214m\u001B[39m\u001B[38;5;214m\u001B[39m\r\n",
      "\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;119m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[0m\u001B[38;5;154m\\\u001B[39m\u001B[0m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[00m\u001B[38;5;214m\u001B[39m\u001B[38;5;214m\u001B[39m\r\n",
      "\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;83m \u001B[39m\u001B[38;5;119m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[0m\u001B[38;5;184m\\\u001B[39m\u001B[0m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[00m\u001B[38;5;208m\u001B[39m\u001B[38;5;208m\u001B[39m\r\n",
      "\u001B[38;5;83m \u001B[39m\u001B[38;5;119m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[0m\u001B[38;5;184m\\\u001B[39m\u001B[0m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;247m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;247m\u001B[38;5;214m█\u001B[39m\u001B[49;39m\u001B[38;5;214m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[00m\u001B[38;5;208m\u001B[39m\u001B[38;5;208m\u001B[39m\r\n",
      "\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;60m\u001B[38;5;184m▄\u001B[39m\u001B[38;5;178m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;247m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;247;38;5;255m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[49m\u001B[38;5;208m▀\u001B[39m\u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[00m\u001B[38;5;208m\u001B[39m\u001B[38;5;208m\u001B[39m\r\n",
      "\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;60m\u001B[38;5;184m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;184m▄\u001B[39m\u001B[48;5;60m\u001B[38;5;178m▄\u001B[39m\u001B[38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;60;38;5;67m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[49;38;5;247m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;247;38;5;255m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;252m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[49m\u001B[38;5;208m▀\u001B[39m\u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[00m\u001B[38;5;209m\u001B[39m\u001B[38;5;203m\u001B[39m\r\n",
      "\u001B[38;5;118m \u001B[39m\u001B[38;5;118m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;184m█\u001B[39m\u001B[38;5;255m\u001B[38;5;178m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;67;38;5;247m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[48;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;67;38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[38;5;247m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;252;38;5;255m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[49m\u001B[38;5;208m▀\u001B[39m\u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;209m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[00m\u001B[38;5;203m\u001B[39m\u001B[38;5;203m\u001B[39m\r\n",
      "\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;214m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;214m█\u001B[39m\u001B[48;5;252m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;255;38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;247;38;5;255m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;247m\u001B[38;5;214m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;208m█\u001B[39m\u001B[38;5;252m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[49;38;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[39m\u001B[38;5;209m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[00m\u001B[38;5;203m\u001B[39m\u001B[38;5;203m\u001B[39m\r\n",
      "\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;214m█\u001B[39m\u001B[48;5;255;38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;252;38;5;67m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;60;38;5;252m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;252;38;5;255m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;252m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255;38;5;16m\u001B[38;5;209m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[49;38;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[00m\u001B[38;5;203m\u001B[39m\u001B[38;5;203m\u001B[39m\r\n",
      "\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;154m \u001B[39m\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60;38;5;255m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;67;38;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;60;38;5;255m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255;38;5;16m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;16m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;255m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[49;38;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[00m\u001B[38;5;204m\u001B[39m\u001B[38;5;198m\u001B[39m\r\n",
      "\u001B[38;5;148m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;60m\u001B[38;5;208m▀\u001B[39m\u001B[48;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[48;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;231;38;5;231m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;67;38;5;252m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;16;38;5;16m\u001B[38;5;203m█\u001B[39m\u001B[48;5;231m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;16m\u001B[38;5;203m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;60m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;247;38;5;255m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;247m\u001B[38;5;204m█\u001B[39m\u001B[49;38;5;60m\u001B[38;5;198m▄\u001B[39m\u001B[39m\u001B[38;5;198m \u001B[39m\u001B[00m\u001B[38;5;198m\u001B[39m\u001B[38;5;198m\u001B[39m\r\n",
      "\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;208m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;231m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;60m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;67;38;5;252m\u001B[38;5;204m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;60m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[49;38;5;67m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;60m\u001B[38;5;198m▀\u001B[39m\u001B[39m\u001B[00m\u001B[38;5;198m\u001B[39m\u001B[38;5;198m\u001B[39m\r\n",
      "\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;214m▄\u001B[39m\u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;60m\u001B[38;5;208m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;209m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;203m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;204m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;252m\u001B[38;5;198m▄\u001B[39m\u001B[49m\u001B[38;5;198m▀\u001B[39m\u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[00m\u001B[38;5;198m\u001B[39m\u001B[38;5;199m\u001B[39m\r\n",
      "\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;184m \u001B[39m\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;60;38;5;67m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[49m\u001B[38;5;208m▄\u001B[39m\u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;209m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;203m█\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;203m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;204m▄\u001B[39m\u001B[38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[49m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;198m█\u001B[39m\u001B[49;39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[00m\u001B[38;5;199m\u001B[39m\u001B[38;5;199m\u001B[39m\r\n",
      "\u001B[38;5;178m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;214m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[49;38;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[39m\u001B[38;5;208m \u001B[39m\u001B[38;5;209m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;60m\u001B[38;5;203m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;203m█\u001B[39m\u001B[48;5;255m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;204m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[49;39m\u001B[38;5;198m \u001B[39m\u001B[38;5;239m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[00m\u001B[38;5;199m\u001B[39m\u001B[38;5;199m\u001B[39m\r\n",
      "\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;214m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;214m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;203m█\u001B[39m\u001B[49;39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;203m█\u001B[39m\u001B[48;5;247m\u001B[38;5;204m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[48;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[48;5;239m\u001B[38;5;199m▄\u001B[39m\u001B[49;38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[00m\u001B[38;5;199m\u001B[39m\u001B[38;5;163m\u001B[39m\r\n",
      "\u001B[38;5;214m \u001B[39m\u001B[38;5;214m \u001B[39m\u001B[38;5;60m\u001B[38;5;214m▄\u001B[39m\u001B[48;5;60;38;5;67m\u001B[38;5;214m▄\u001B[39m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;60;38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[49m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;204m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;198m█\u001B[39m\u001B[48;5;235m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;239;38;5;235m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;239m\u001B[38;5;198m█\u001B[39m\u001B[48;5;235m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;255;38;5;59m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;255;38;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;235m\u001B[38;5;199m█\u001B[39m\u001B[49;39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[00m\u001B[38;5;164m\u001B[39m\u001B[38;5;164m\u001B[39m\r\n",
      "\u001B[38;5;214m \u001B[39m\u001B[38;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;60;38;5;67m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60m\u001B[38;5;208m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;208m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;204m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;198m█\u001B[39m\u001B[48;5;239m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;59;38;5;59m\u001B[38;5;199m█\u001B[39m\u001B[48;5;246;38;5;246m\u001B[38;5;199m█\u001B[39m\u001B[38;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;59m\u001B[38;5;199m█\u001B[39m\u001B[38;5;246m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;246;38;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;59m\u001B[38;5;199m█\u001B[39m\u001B[48;5;239;38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[49m\u001B[38;5;199m▀\u001B[39m\u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[00m\u001B[38;5;164m\u001B[39m\u001B[38;5;164m\u001B[39m\r\n",
      "\u001B[38;5;208m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;208m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;203m█\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;203m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;222m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;204m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;235m\u001B[38;5;198m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;246;38;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;59;38;5;255m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;222m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;246;38;5;59m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;59;38;5;239m\u001B[38;5;163m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;163m▄\u001B[39m\u001B[38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[00m\u001B[38;5;164m\u001B[39m\u001B[38;5;164m\u001B[39m\r\n",
      "\u001B[38;5;208m \u001B[39m\u001B[38;5;60m\u001B[38;5;208m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;208m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;208m█\u001B[39m\u001B[38;5;209m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;60m\u001B[38;5;203m▄\u001B[39m\u001B[49m\u001B[38;5;203m▀\u001B[39m\u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;60m\u001B[38;5;203m▀\u001B[39m\u001B[48;5;67;38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;203m█\u001B[39m\u001B[38;5;235m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;222m\u001B[38;5;204m▄\u001B[39m\u001B[48;5;222m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;255;38;5;235m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;222;38;5;222m\u001B[38;5;198m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;198m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;239m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;199m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;199m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;163m█\u001B[39m\u001B[38;5;222m\u001B[38;5;163m▄\u001B[39m\u001B[48;5;247;38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;164m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[00m\u001B[38;5;164m\u001B[39m\u001B[38;5;128m\u001B[39m\r\n",
      "\u001B[38;5;208m \u001B[39m\u001B[38;5;209m \u001B[39m\u001B[38;5;60m\u001B[38;5;203m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;60m\u001B[38;5;203m▄\u001B[39m\u001B[49;38;5;60m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;203m█\u001B[39m\u001B[38;5;239m\u001B[38;5;203m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;203m█\u001B[39m\u001B[38;5;204m█\u001B[39m\u001B[38;5;235m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;235;38;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;222m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;199m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;199m█\u001B[39m\u001B[38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;163m█\u001B[39m\u001B[48;5;239m\u001B[38;5;163m▄\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;164m█\u001B[39m\u001B[48;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;255;38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;164m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[00m\u001B[38;5;129m\u001B[39m\u001B[38;5;129m\u001B[39m\r\n",
      "\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;60m\u001B[38;5;203m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;203m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[38;5;203m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;203m█\u001B[39m\u001B[49;39m\u001B[38;5;204m \u001B[39m\u001B[38;5;235m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[48;5;235;38;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[49m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;247;38;5;255m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;247m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;247m\u001B[38;5;199m█\u001B[39m\u001B[38;5;252m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;255;38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[38;5;235m\u001B[38;5;199m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;163m█\u001B[39m\u001B[38;5;235m\u001B[38;5;163m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;164m█\u001B[39m\u001B[38;5;67m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[49;38;5;235m\u001B[38;5;164m▀\u001B[39m\u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[00m\u001B[38;5;129m\u001B[39m\u001B[38;5;129m\u001B[39m\r\n",
      "\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;203m█\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;204m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;198m█\u001B[39m\u001B[49;39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;247;38;5;252m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;252m\u001B[38;5;199m█\u001B[39m\u001B[38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[49m\u001B[38;5;199m▀\u001B[39m\u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;235m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;235;38;5;239m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;163m█\u001B[39m\u001B[38;5;163m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[48;5;60;38;5;239m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;235m\u001B[38;5;164m▄\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[00m\u001B[38;5;129m\u001B[39m\u001B[38;5;129m\u001B[39m\r\n",
      "\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;203m \u001B[39m\u001B[38;5;204m \u001B[39m\u001B[38;5;60m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;60;38;5;67m\u001B[38;5;198m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;198m█\u001B[39m\u001B[48;5;60;38;5;60m\u001B[38;5;198m█\u001B[39m\u001B[49;39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;198m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;198m█\u001B[39m\u001B[38;5;198m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;247;38;5;252m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;252m\u001B[38;5;199m█\u001B[39m\u001B[38;5;247m\u001B[38;5;199m▄\u001B[39m\u001B[49m\u001B[38;5;199m▀\u001B[39m\u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;163m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[48;5;239m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[00m\u001B[38;5;93m\u001B[39m\u001B[38;5;93m\u001B[39m\r\n",
      "\u001B[38;5;203m \u001B[39m\u001B[38;5;204m \u001B[39m\u001B[38;5;60m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[48;5;60m\u001B[38;5;198m█\u001B[39m\u001B[48;5;67m\u001B[38;5;198m▄\u001B[39m\u001B[49m\u001B[38;5;198m▀\u001B[39m\u001B[38;5;198m▀\u001B[39m\u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;252;38;5;252m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[49;39m\u001B[38;5;163m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[38;5;239m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;239;38;5;235m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;235m\u001B[38;5;164m█\u001B[39m\u001B[48;5;239;38;5;239m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;128m█\u001B[39m\u001B[38;5;128m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;129m█\u001B[39m\u001B[49;39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[00m\u001B[38;5;93m\u001B[39m\u001B[38;5;93m\u001B[39m\r\n",
      "\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;252;38;5;252m\u001B[38;5;163m█\u001B[39m\u001B[38;5;163m█\u001B[39m\u001B[48;5;247;38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;164m█\u001B[39m\u001B[48;5;222;38;5;239m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;239m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[48;5;235;38;5;235m\u001B[38;5;128m█\u001B[39m\u001B[38;5;252m\u001B[38;5;128m▄\u001B[39m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;252m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;247m\u001B[38;5;129m▄\u001B[39m\u001B[49;39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[00m\u001B[38;5;93m\u001B[39m\u001B[38;5;93m\u001B[39m\r\n",
      "\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[48;5;247;38;5;247m\u001B[38;5;199m█\u001B[39m\u001B[48;5;255;38;5;255m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;199m█\u001B[39m\u001B[38;5;67m\u001B[38;5;163m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;163m█\u001B[39m\u001B[48;5;247;38;5;67m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[48;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[49;38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[48;5;235;38;5;247m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;128m▄\u001B[39m\u001B[38;5;67m\u001B[38;5;128m▄\u001B[39m\u001B[38;5;255m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;247m\u001B[38;5;129m▄\u001B[39m\u001B[48;5;67;38;5;67m\u001B[38;5;129m█\u001B[39m\u001B[48;5;252m\u001B[38;5;129m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[48;5;60m\u001B[38;5;129m▄\u001B[39m\u001B[49;38;5;60m\u001B[38;5;129m▄\u001B[39m\u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[00m\u001B[38;5;99m\u001B[39m\u001B[38;5;63m\u001B[39m\r\n",
      "\u001B[38;5;198m \u001B[39m\u001B[38;5;198m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[48;5;247;38;5;67m\u001B[38;5;199m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;163m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;163m█\u001B[39m\u001B[48;5;255m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;60m\u001B[38;5;164m▄\u001B[39m\u001B[38;5;164m▄\u001B[39m\u001B[48;5;60m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[48;5;247;38;5;67m\u001B[38;5;128m▄\u001B[39m\u001B[48;5;255m\u001B[38;5;128m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;129m█\u001B[39m\u001B[48;5;255m\u001B[38;5;129m▄\u001B[39m\u001B[48;5;67m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;60m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;129m▄\u001B[39m\u001B[38;5;93m▄\u001B[39m\u001B[48;5;60m\u001B[38;5;93m█\u001B[39m\u001B[49;39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;99m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[00m\u001B[38;5;63m\u001B[39m\u001B[38;5;63m\u001B[39m\r\n",
      "\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;67m\u001B[38;5;164m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[38;5;164m█\u001B[39m\u001B[49;39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;67m\u001B[38;5;129m▀\u001B[39m\u001B[48;5;67m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[38;5;129m█\u001B[39m\u001B[49;39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;99m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[00m\u001B[38;5;63m\u001B[39m\u001B[38;5;63m\u001B[39m\r\n",
      "\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;199m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;163m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;164m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;128m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;129m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;93m \u001B[39m\u001B[38;5;99m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[38;5;63m \u001B[39m\u001B[00m\u001B[38;5;63m\u001B[39m\u001B[38;5;63m\u001B[39m\r\n",
      "\u001B[m\u001B[?25h\u001B[?1;5;2004lDefaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 12.0 MB 2.9 MB/s eta 0:00:01    |█▋                              | 593 kB 2.9 MB/s eta 0:00:04\r\n",
      "\u001B[?25hCollecting torch\r\n",
      "  Downloading torch-2.8.0-cp39-none-macosx_11_0_arm64.whl (73.6 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 73.6 MB 44.1 MB/s eta 0:00:01    |▋                               | 1.5 MB 11.1 MB/s eta 0:00:07     |██▎                             | 5.2 MB 11.1 MB/s eta 0:00:07     |██████                          | 14.0 MB 11.1 MB/s eta 0:00:06     |██████████▉                     | 25.0 MB 11.1 MB/s eta 0:00:05     |███████████▋                    | 26.8 MB 11.1 MB/s eta 0:00:05     |█████████████████               | 39.1 MB 39.8 MB/s eta 0:00:01     |█████████████████████           | 48.2 MB 39.8 MB/s eta 0:00:01     |█████████████████████▊          | 50.1 MB 39.8 MB/s eta 0:00:01     |█████████████████████████████   | 66.7 MB 39.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting tqdm>=4.27\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 78 kB 13.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting safetensors>=0.4.3\r\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 432 kB 62.7 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting regex!=2019.12.17\r\n",
      "  Downloading regex-2025.10.23-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 288 kB 51.6 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting tokenizers<=0.23.0,>=0.22.0\r\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.9 MB 52.8 MB/s eta 0:00:01     |███▋                            | 327 kB 52.8 MB/s eta 0:00:01     |█████████████████████████       | 2.3 MB 52.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from transformers) (25.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.34.0\r\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 566 kB 26.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.4)\r\n",
      "Collecting filelock\r\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\r\n",
      "Collecting fsspec\r\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 200 kB 28.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting networkx\r\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 47.1 MB/s eta 0:00:01     |███████████████████████████████▏| 1.6 MB 47.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from torch) (4.14.1)\r\n",
      "Collecting sympy>=1.13.3\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 6.3 MB 35.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting hf-xet<2.0.0,>=1.1.3\r\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.7 MB 21.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting mpmath<1.4,>=1.1.0\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 536 kB 34.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.7.14)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Installing collected packages: tqdm, hf-xet, fsspec, filelock, mpmath, huggingface-hub, tokenizers, sympy, safetensors, regex, networkx, transformers, torch\r\n",
      "\u001B[33m  WARNING: The script tqdm is installed in '/Users/nitin.sharma/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\r\n",
      "\u001B[33m  WARNING: The scripts hf, huggingface-cli and tiny-agents are installed in '/Users/nitin.sharma/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\r\n",
      "\u001B[33m  WARNING: The script isympy is installed in '/Users/nitin.sharma/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\r\n",
      "\u001B[33m  WARNING: The scripts transformers and transformers-cli are installed in '/Users/nitin.sharma/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\r\n",
      "\u001B[33m  WARNING: The scripts torchfrtrace and torchrun are installed in '/Users/nitin.sharma/Library/Python/3.9/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\r\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.2.1 regex-2025.10.23 safetensors-0.6.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.57.1\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\r\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/nitin.sharma/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input IDs: tensor([[  101,  1996,  4937,  2938,  2006,  1996, 13523,  1012,   102]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Sentence Embedding Shape: torch.Size([1, 768])\n",
      "Sentence Embedding Vector: tensor([[-1.8180e-01, -2.6618e-01, -2.1887e-01,  2.1089e-01,  2.8473e-01,\n",
      "         -1.7185e-01, -1.6588e-01,  5.0974e-01, -1.2715e-01, -1.6971e-01,\n",
      "          3.0352e-02, -4.6905e-01, -3.5898e-02,  1.3398e-01, -1.1766e-01,\n",
      "         -2.4077e-01,  1.2072e-01,  5.9154e-02, -3.9102e-01,  1.0781e-01,\n",
      "          2.3168e-01, -2.0653e-01, -5.2181e-01,  9.9232e-02,  2.9413e-01,\n",
      "         -2.4380e-01,  7.1086e-02, -1.4326e-01, -5.0724e-02, -2.2996e-02,\n",
      "          2.1027e-01, -5.6707e-02, -1.4975e-01, -2.7953e-01,  5.4398e-02,\n",
      "         -8.8523e-02,  2.9781e-01,  3.1730e-01, -5.4683e-01,  2.3623e-01,\n",
      "         -3.6286e-01, -1.8020e-01,  2.5657e-02,  5.8190e-01,  4.0848e-01,\n",
      "         -2.3206e-01,  4.0671e-01, -2.0782e-01,  6.3488e-01,  1.6949e-01,\n",
      "         -6.2998e-01,  3.3577e-01, -2.8222e-02,  1.0912e-01, -3.3112e-02,\n",
      "          6.6778e-01,  2.2382e-01, -3.4467e-01, -1.0597e-02,  3.8314e-01,\n",
      "         -6.3685e-02,  4.3446e-01,  1.9478e-01, -5.2195e-01, -2.3798e-01,\n",
      "          4.4900e-01, -6.2229e-02,  2.0469e-01, -3.8803e-01,  2.6863e-01,\n",
      "         -4.2530e-01, -3.8221e-01, -1.1183e-01,  3.4520e-02,  3.5490e-02,\n",
      "          3.3936e-02,  1.3373e-02,  3.4056e-01,  3.3538e-01,  7.5321e-03,\n",
      "         -2.4909e-01,  7.3309e-01, -5.0393e-02,  4.0413e-01,  1.5924e-01,\n",
      "         -9.6005e-02, -3.5544e-01, -3.2521e-01, -4.9352e-01,  3.9558e-01,\n",
      "         -4.1028e-01, -2.2501e-02, -3.1151e-01,  5.4961e-01, -3.4199e-03,\n",
      "          3.4299e-01,  1.4100e-01, -1.2401e-01,  1.8118e-01,  3.1187e-01,\n",
      "          2.7959e-01, -4.7075e-02,  3.9381e-01,  5.5641e-01, -1.9630e-01,\n",
      "         -5.3562e-01,  2.2281e-01, -7.3732e-02, -3.0736e-01,  5.4388e-02,\n",
      "         -7.6831e-02, -4.4882e-01,  3.4053e-01, -9.0910e-02, -3.0797e-02,\n",
      "          7.9998e-01, -1.2165e-01,  1.0552e-02, -2.7447e-01,  1.5263e-01,\n",
      "         -6.9458e-02, -3.7851e-01, -2.9470e-02,  6.5597e-01,  1.0721e-02,\n",
      "          9.9605e-02, -2.2720e-01, -1.3291e-02,  1.2819e-01, -5.4876e-01,\n",
      "          3.8863e-01,  6.1657e-01,  1.8163e-01, -7.4544e-01, -1.9307e-01,\n",
      "          6.9152e-01,  4.8539e-01,  2.7766e-02, -8.7722e-01,  1.3045e-01,\n",
      "          2.8806e-01, -1.0507e-01,  2.2219e-01,  1.7836e-01,  7.5351e-01,\n",
      "          2.5732e-01, -8.6775e-02, -3.6772e-01,  6.5945e-02,  2.5172e-01,\n",
      "          2.3804e-01, -5.2963e-02, -1.4164e-01, -2.6934e-01, -3.5502e-01,\n",
      "         -4.6631e-02, -2.1760e-01,  2.8432e-01,  2.7232e-01,  1.2819e-01,\n",
      "          4.1904e-01, -4.2988e-01, -1.3727e-01,  1.2675e-01, -6.3968e-02,\n",
      "          2.6335e-01, -5.5488e-02,  4.2207e-01, -4.1365e-03,  3.3108e-01,\n",
      "         -4.3492e-01,  2.2446e-01,  9.7977e-01, -3.1159e-01, -2.7761e-01,\n",
      "         -1.3163e-01, -1.9154e-01, -2.1462e-01, -3.6309e-01,  1.8386e-01,\n",
      "         -1.4444e+00,  2.0277e-01,  3.5538e-01,  5.0478e-02,  2.4624e-01,\n",
      "         -2.5637e-01,  6.2883e-01, -7.8285e-01, -3.5927e-01,  3.1781e-01,\n",
      "          1.1742e-01, -4.9752e-01, -5.9380e-01,  1.6202e-01,  5.0663e-01,\n",
      "         -6.3019e-01, -5.5565e-01, -7.1649e-01, -2.2751e-01, -2.0529e-01,\n",
      "          1.0508e-01, -5.5261e-01,  3.3865e-01,  3.1490e-01,  2.3746e-01,\n",
      "          2.0914e-01, -1.7940e-01, -2.9223e-01, -2.8091e-01,  4.0636e-01,\n",
      "         -3.7665e-01,  4.4192e-01,  2.3523e-01,  4.7021e-01,  2.8296e-01,\n",
      "         -3.0547e-02,  1.8078e-01,  2.1675e-01, -2.1941e-01,  2.0466e-01,\n",
      "          1.8459e-02,  2.1619e-01, -6.3532e-01,  5.7675e-01, -6.3234e-02,\n",
      "          1.3103e+00, -9.1453e-03, -1.5545e-01, -2.5181e-01,  6.3300e-01,\n",
      "          2.1394e-02, -1.0536e-03,  5.0959e-01,  5.6181e-01, -4.2664e-01,\n",
      "         -2.3251e-01, -4.5527e-01, -2.1833e-01,  5.1528e-02, -1.3741e-01,\n",
      "         -1.2998e-01,  2.5672e-01,  9.5764e-01, -1.8243e-01,  1.4505e-01,\n",
      "          9.2458e-02,  1.7922e-01,  3.9997e-01, -3.5114e-01, -4.9639e-01,\n",
      "          2.4190e-01, -6.4145e-01,  9.3477e-02, -8.8054e-01, -4.0972e-01,\n",
      "         -3.3682e-01, -5.1631e-01,  7.5997e-02,  5.7855e-03,  2.6265e-01,\n",
      "          5.2102e-01, -2.1065e-02,  8.0029e-01, -2.8990e-01, -3.5990e-02,\n",
      "         -8.0460e-02,  5.1703e-01,  1.7001e-01, -3.1078e-01, -3.4855e-01,\n",
      "          3.3556e-01, -3.4285e-01,  3.6209e-01,  1.6169e-02, -4.8038e-01,\n",
      "         -2.8854e-01,  3.7499e-01, -1.5153e-01,  1.4228e-01, -6.9191e-01,\n",
      "          2.2381e-01,  5.0632e-01, -8.1507e-01,  6.1169e-02,  1.5172e-01,\n",
      "         -6.8361e-01, -9.4352e-02, -3.9221e-03, -7.7626e-02, -3.5472e-01,\n",
      "          1.6956e-02,  5.9929e-01, -1.6488e-01, -3.3955e-01, -5.2725e-01,\n",
      "          7.4708e-02,  8.2415e-02,  4.4449e-01,  2.6306e-01, -8.6217e-02,\n",
      "         -6.4435e-02, -1.5523e-01,  5.7723e-02,  3.4809e-01, -7.3449e-02,\n",
      "         -1.6260e-01, -8.1059e-02, -1.0386e-01, -2.8010e+00,  2.0187e-01,\n",
      "          1.9738e-01, -8.1534e-02,  5.9201e-01, -6.2804e-03, -1.9555e-01,\n",
      "         -3.0112e-01, -8.3316e-01,  2.2188e-01,  1.1744e-01, -4.2947e-01,\n",
      "          6.9756e-01,  4.4782e-01,  3.7165e-01, -4.1186e-01,  1.9253e-01,\n",
      "         -3.3823e-01, -1.9667e-01,  2.8810e-01, -4.4229e-01, -6.7798e-01,\n",
      "         -1.9688e-01, -7.5271e-01,  2.8145e-01,  9.5801e-01,  4.2333e-02,\n",
      "          2.1086e-01, -5.8779e-01, -2.9930e-01, -1.3813e-01, -6.7276e-02,\n",
      "          2.9040e-01, -2.3558e-01,  1.5075e-01, -1.0112e-01,  2.6810e-01,\n",
      "         -2.0281e-01,  5.8822e-02,  2.7638e-01, -1.9381e-01,  1.4305e-01,\n",
      "          2.4323e-01,  2.8183e-01,  7.6759e-01,  2.1849e-02, -3.2285e-01,\n",
      "         -6.3984e-01,  5.1559e-02,  5.0712e-01,  1.9714e-01,  2.0228e-02,\n",
      "         -4.1199e-01,  2.3750e-03,  2.0567e-01, -1.7810e-01,  3.6253e-01,\n",
      "         -1.2272e-01, -5.1544e-01, -3.3257e-01,  3.0418e-02, -4.2342e-01,\n",
      "         -5.4119e-02,  5.0214e-01,  1.8367e-01, -2.7864e-01, -4.0269e-01,\n",
      "         -5.2195e-01,  2.9518e-01,  2.6127e-01, -1.1443e-01, -2.1813e-01,\n",
      "         -4.3794e-01, -1.0423e+00, -5.2256e-01,  2.1939e-01,  4.0848e-01,\n",
      "         -4.0668e-01,  9.8806e-02, -4.5942e-01, -1.4165e-01, -7.7179e-01,\n",
      "         -1.5175e-01, -2.5724e-01, -3.5210e-01, -9.1775e-01,  1.5176e-01,\n",
      "         -4.2168e-01, -2.8450e-01, -4.5297e-01, -7.6861e-02,  3.9813e-01,\n",
      "          5.2478e-02,  3.0200e-01,  8.3216e-02, -1.7473e-01,  2.7818e-01,\n",
      "         -5.3749e-01, -1.7460e-01,  1.5869e-02, -1.1746e-01, -4.0099e-01,\n",
      "          1.5436e-01,  4.9337e-01,  4.7555e-03,  1.7125e-01, -6.2344e-01,\n",
      "         -2.2668e-01, -1.8897e-01,  9.4951e-02,  1.5982e-01, -7.9984e-01,\n",
      "          6.7358e-01, -3.7375e-01, -1.3326e-02, -7.9682e-02,  6.0536e-01,\n",
      "          4.1966e-01, -3.8237e-01,  1.2825e-01,  3.4543e-01,  3.3541e-01,\n",
      "          1.1520e-03, -2.6172e-01, -1.5828e-01, -1.6380e-01,  5.3633e-02,\n",
      "         -7.9598e-01, -1.7977e-01, -1.1096e-01,  1.0655e-01, -3.9408e-01,\n",
      "          7.0108e-02,  2.7183e-01,  2.1945e-01, -2.7339e-01, -6.9180e-01,\n",
      "         -8.3987e-01,  3.3651e-01,  1.3104e-01, -4.6212e-01,  4.4273e-01,\n",
      "          8.0083e-02, -5.8214e-02, -2.2767e-01,  2.5426e-01,  2.9738e-01,\n",
      "         -2.8467e-01, -2.3713e-01,  4.6597e-01, -2.8731e-01,  8.3956e-02,\n",
      "          1.8518e-01, -6.3584e-02,  1.0637e-01, -3.8968e-01,  7.3266e-01,\n",
      "         -1.7899e-01,  1.5397e-01, -4.3563e-01, -2.1165e-01,  1.1570e-01,\n",
      "          5.2629e-01,  4.0577e-01, -2.2937e-01,  1.7624e-01,  6.4670e-01,\n",
      "          2.8960e-01, -1.1457e-01,  4.1703e-01, -6.1832e-02, -4.1925e-01,\n",
      "          6.3938e-03,  4.8000e-01, -5.5363e-01,  3.9111e-01, -7.9442e-02,\n",
      "         -4.9003e-01, -5.9950e-01,  1.3111e-01, -6.9069e-02, -1.0919e-01,\n",
      "         -6.4848e-01, -9.7921e-02,  1.9918e-01,  3.7299e-01,  1.5409e-02,\n",
      "         -3.7443e-01,  2.6693e-01,  2.1462e-01,  3.8449e-02,  6.0391e-01,\n",
      "         -1.7011e-01, -1.2340e-01, -1.0755e+00, -2.9202e-01,  1.1520e-01,\n",
      "          2.4288e-01,  3.7333e-01, -2.4075e-01,  2.7568e-01,  2.5996e-01,\n",
      "         -9.9100e-02, -1.0136e-01, -1.7232e-01, -4.7763e-01,  3.1247e-01,\n",
      "         -1.9466e-01, -1.6855e-01,  5.9275e-02, -4.2303e-01, -6.5450e-01,\n",
      "         -5.5392e-01, -6.3400e-01,  3.0351e-01,  4.8076e-01,  3.1405e-01,\n",
      "         -2.2940e-01,  1.7346e-01, -4.4485e-02, -6.5256e-01, -6.6590e-02,\n",
      "         -1.5051e-01, -4.3322e-01, -7.4733e-01, -1.0733e-01,  7.7828e-02,\n",
      "         -1.1268e-01, -2.9509e-01,  1.0487e-01,  1.5823e-01, -1.3865e-01,\n",
      "          1.5776e-01, -9.4106e-02,  5.6690e-01, -2.6907e-02, -3.0334e-01,\n",
      "         -3.2802e-01,  1.6007e-01,  3.2341e-02,  4.8107e-01,  1.7140e-01,\n",
      "          3.3999e-01, -3.7224e-01,  1.0081e-01, -3.2237e-01,  7.0938e-02,\n",
      "          4.3762e-01, -2.2147e-01,  2.0318e-01,  8.9556e-03,  4.1629e-01,\n",
      "         -1.1936e-01, -3.3468e-01, -2.0736e-01,  4.8975e-03, -3.8980e-01,\n",
      "          1.0930e-01,  2.5941e-01,  2.7195e-01,  5.1520e-02, -2.3167e-01,\n",
      "         -1.8102e-01,  3.8293e-01,  2.3807e-01, -1.0787e-01,  8.4143e-02,\n",
      "         -3.1401e-01,  3.6324e-01, -1.4717e-01,  1.6023e-02, -3.0932e-01,\n",
      "          1.2239e-01, -2.3950e-01, -3.1151e-01,  1.5949e-01,  4.0237e-01,\n",
      "         -9.7055e-01, -6.9758e-02, -3.8795e-01,  7.1728e-02,  6.0893e-01,\n",
      "         -1.8324e-01,  1.7957e-01, -5.4900e-01, -7.9425e-02, -3.8853e-01,\n",
      "          2.2397e-01, -3.7232e-01, -1.4456e-01,  2.7117e-01,  9.1982e-02,\n",
      "          3.4789e-01,  3.7932e-01,  1.7648e-02,  2.6442e-01,  4.7837e-01,\n",
      "          2.5697e-01, -1.2676e-01,  2.0253e-01, -4.4516e-01,  4.7409e-01,\n",
      "          3.3851e-01,  1.4821e-01, -7.0850e-02,  1.0430e-01,  7.3687e-02,\n",
      "         -2.0868e-01, -1.5762e-02,  2.5240e-01, -1.1055e-01, -2.3645e-01,\n",
      "          4.6166e-01,  4.8103e-01, -7.4401e-01,  2.4899e-01, -3.9597e-01,\n",
      "         -2.7084e-01, -2.3521e-01,  3.1707e-01,  2.2322e-01, -2.4710e-01,\n",
      "          2.5126e-01, -2.3708e-02,  2.3607e-01,  6.9342e-01, -5.6823e-01,\n",
      "          1.8407e-01,  2.9944e-01, -1.6406e-01, -3.0632e-01,  4.1097e-01,\n",
      "          2.7652e-01, -2.2538e-02,  1.3380e-01, -3.4514e-01,  3.0766e-02,\n",
      "          5.0891e-01,  8.8038e-02, -5.1622e-01, -4.0309e-03,  5.9626e-02,\n",
      "          3.2955e-01,  2.5616e-01,  3.9327e-01, -2.7030e-01,  1.6456e-01,\n",
      "         -5.9425e-01,  6.6523e-01,  1.6039e-01,  2.8778e-01,  3.2813e-01,\n",
      "          3.2880e-02, -1.7606e-01,  3.5365e-01,  4.7375e-01,  1.9747e-01,\n",
      "          7.9976e-02, -1.5170e-01,  4.0311e-01,  5.5339e-01,  7.0478e-01,\n",
      "          1.7651e-01, -3.3746e-01, -6.0561e-02,  7.1096e-01, -7.0139e-02,\n",
      "         -6.6897e-01, -3.3383e-01,  8.8806e-03,  6.0813e-01,  3.1335e-01,\n",
      "          7.3599e-01,  1.0772e-01,  7.6671e-02,  6.0194e-01,  2.1698e-01,\n",
      "         -3.7470e-01, -4.8618e-01,  3.4693e-01,  2.3011e-01,  1.6590e-01,\n",
      "         -5.1093e-01, -4.1763e-01,  1.9416e-01, -1.8764e-01,  4.1427e-03,\n",
      "         -2.6532e-03,  1.9557e-01, -2.1351e-01,  1.7440e-02, -2.4724e-01,\n",
      "          6.0631e-01, -4.6106e-01,  2.3903e-02, -2.2756e-01,  5.0013e-01,\n",
      "          1.4496e-01,  2.4658e-01, -1.3996e-01,  4.9501e-01, -4.6521e-01,\n",
      "         -2.8496e-01,  1.1278e-01,  8.4733e-02, -4.6487e-02, -2.2940e-01,\n",
      "         -2.7320e-01, -1.0565e-01, -4.7150e-01, -1.1779e-01,  4.7523e-01,\n",
      "         -7.0713e-01,  4.5822e-02,  1.4060e-01, -6.1576e-02,  6.3198e-02,\n",
      "          4.5912e-02, -6.2184e-01,  5.2689e-01,  1.7236e-01, -3.0194e-02,\n",
      "          6.5080e-02,  3.9355e-01, -5.5543e-01, -5.3011e-01,  6.7696e-01,\n",
      "          5.0494e-01,  6.8723e-02, -1.1764e-01, -3.9860e-01,  3.4340e-01,\n",
      "          5.9922e-02, -1.8813e-01, -1.6446e-01,  1.1582e-02, -4.1465e-02,\n",
      "          4.8620e-02, -2.3613e-01, -4.7705e-01,  1.6632e-01, -1.5508e-01,\n",
      "          3.8427e-01,  3.5926e-01, -7.6859e-01, -4.6089e-01, -2.7690e-01,\n",
      "         -4.8478e-01,  3.0774e-01, -6.7386e-01,  1.2245e-01,  3.2314e-01,\n",
      "         -6.0866e-02, -3.8581e-01,  6.7434e-02, -2.3499e-01, -1.7648e-01,\n",
      "         -1.4755e-01,  4.0146e-01, -3.5041e-02]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdNYbHZ0PMaM"
   },
   "source": [
    "## Text Classification with BERT\n",
    "Let’s use the Hugging Face Transformers library to fine-tune BERT for text classification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AP-5cLltPMaM",
    "outputId": "4ba9a058-f8e1-47b6-bec5-d753bbf68f80",
    "ExecuteTime": {
     "end_time": "2025-10-30T19:52:25.364162Z",
     "start_time": "2025-10-30T19:52:23.702989Z"
    }
   },
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model for classification\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Example input text\n",
    "texts = [\"I love this product!\", \"The movie was terrible.\"]\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Convert logits to probabilities and predictions\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "predictions = torch.argmax(probs, dim=1)\n",
    "\n",
    "print(\"Probabilities:\", probs)\n",
    "print(\"Predictions:\", predictions)  # 0 for negative, 1 for positive\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.4816, 0.5184],\n",
      "        [0.5294, 0.4706]])\n",
      "Predictions: tensor([1, 0])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dy1OexKPMaM"
   },
   "source": [
    "## Text Generation with GPT\n",
    "Let’s generate text using a pre-trained GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS5p-lsSPMaM",
    "outputId": "5d91099a-c11b-448e-ed3f-b49074073746"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Once upon a time in a faraway land, a man named Tiberius, who had been a soldier in the army of the Romans, was sent to the city of Rome to be a priest. He was a man of great wealth and great\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Once upon a time in a faraway land,\"\n",
    "\n",
    "# Tokenize the input prompt\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(inputs, max_length=50, do_sample=True, temperature=0.1)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic Code: Text Classification with BERT.\n",
    "The easiest way to use BERT is with the Hugging Face transformers library. This code shows how to load a pre-trained BERT that has already been fine-tuned for sentiment analysis and use it to make a prediction."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T20:07:36.128647Z",
     "start_time": "2025-10-30T20:07:35.215970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, you need to install the libraries:\n",
    "# pip install torch transformers\n",
    "\n",
    "import torch\n",
    "# Import the \"Auto\" classes\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load a Tokenizer and a Model\n",
    "# We're loading a DistilBERT model, so we let \"Auto\" figure it out\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# AutoTokenizer will load DistilBertTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# AutoModelForSequenceClassification will load DistilBertForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 2. Define your text\n",
    "text = \"I hate this movie. The acting was shit!\"\n",
    "# Try changing this text to: \"This was the worst film I have ever seen.\"\n",
    "\n",
    "# 3. Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "print(\"--- Tokenizer Output ---\")\n",
    "print(\"Input IDs:\", inputs['input_ids'])\n",
    "print(\"Attention Mask:\", inputs['attention_mask'])\n",
    "print(\"--------------------------\\n\")\n",
    "\n",
    "# 4. Get the Prediction (Inference)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# 5. Interpret the Output\n",
    "logits = outputs.logits\n",
    "print(\"Raw Logits:\", logits)\n",
    "\n",
    "predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# The model's config tells us what the class labels mean\n",
    "# For this model: {0: 'NEGATIVE', 1: 'POSITIVE'}\n",
    "predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(f\"\\nText: '{text}'\")\n",
    "print(f\"Predicted Sentiment: {predicted_label} (ID: {predicted_class_id})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tokenizer Output ---\n",
      "Input IDs: tensor([[ 101, 1045, 5223, 2023, 3185, 1012, 1996, 3772, 2001, 4485,  999,  102]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "--------------------------\n",
      "\n",
      "Raw Logits: tensor([[ 4.3654, -3.5200]])\n",
      "\n",
      "Text: 'I hate this movie. The acting was shit!'\n",
      "Predicted Sentiment: NEGATIVE (ID: 0)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Other Sample Examples of BERT Applications"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T20:16:17.182932Z",
     "start_time": "2025-10-30T20:15:36.196072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install the necessary libraries if you haven't already\n",
    "# !pip install torch transformers\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, BertModel, BertTokenizer\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    \"\"\"Helper function to print Markdown in a notebook cell.\"\"\"\n",
    "    display(Markdown(string))\n",
    "\n",
    "printmd(\"## ✅ BERT Applications Code Examples (using Hugging Face Transformers)\")\n",
    "printmd(\"---\")\n",
    "\n",
    "## 1. ❓ Question Answering (Q&A) Example\n",
    "\n",
    "printmd(\"### 1. Question Answering (Q&A)\")\n",
    "\n",
    "# Initialize the Question Answering pipeline\n",
    "# Uses a model fine-tuned for Q&A (SQuAD dataset)\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"distilbert-base-cased-distilled-squad\",\n",
    "    tokenizer=\"distilbert-base-cased-distilled-squad\"\n",
    ")\n",
    "\n",
    "# Define the context and question\n",
    "context = (\n",
    "    \"The 2024 Summer Olympics were held in Paris, France. \"\n",
    "    \"These games featured the introduction of breakdancing as an official sport, \"\n",
    "    \"and the United States topped the medal count for the second consecutive time.\"\n",
    ")\n",
    "question = \"Which new sport was introduced at the 2024 Olympics?\"\n",
    "\n",
    "# Get the prediction\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "printmd(f\"**Context:** {context}\")\n",
    "printmd(f\"**Question:** *{question}*\")\n",
    "printmd(f\"**BERT's Extracted Answer:** **{result['answer']}**\")\n",
    "printmd(f\"**Confidence Score:** {result['score']:.4f}\")\n",
    "\n",
    "printmd(\"---\")\n",
    "\n",
    "\n",
    "## 2. 🏷️ Named Entity Recognition (NER) Example\n",
    "\n",
    "printmd(\"### 2. Named Entity Recognition (NER)\")\n",
    "\n",
    "# Initialize the Named Entity Recognition pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "# Define the input text\n",
    "text = \"Angela Merkel met with the CEO of Siemens in Berlin yesterday.\"\n",
    "\n",
    "# Get the prediction\n",
    "results = ner_pipeline(text)\n",
    "\n",
    "printmd(f\"**Input Text:** {text}\")\n",
    "printmd(\"**Identified Entities:**\")\n",
    "\n",
    "for entity in results:\n",
    "    printmd(\n",
    "        f\"* **Entity:** **{entity['word']}** \"\n",
    "        f\"(Type: `{entity['entity_group']}`, Score: {entity['score']:.4f})\"\n",
    "    )\n",
    "\n",
    "printmd(\"---\")\n",
    "\n",
    "\n",
    "## 3. 🧠 Feature Extraction (Embeddings) Example\n",
    "\n",
    "printmd(\"### 3. Feature Extraction (Sentence Embeddings)\")\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Define the text\n",
    "text = \"BERT is a powerful language model.\"\n",
    "\n",
    "# Tokenize and prepare input\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Get the model output\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# The embedding for the [CLS] token (at index 0) is used as the sentence embedding.\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "printmd(f\"**Input Text:** '{text}'\")\n",
    "printmd(f\"**Sentence Embedding Shape (Vector Size):** {sentence_embedding.shape}\")\n",
    "printmd(f\"**First 5 dimensions of the 768-dim vector:**\")\n",
    "print(sentence_embedding[0, :5].numpy())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## ✅ BERT Applications Code Examples (using Hugging Face Transformers)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "---"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### 1. Question Answering (Q&A)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Context:** The 2024 Summer Olympics were held in Paris, France. These games featured the introduction of breakdancing as an official sport, and the United States topped the medal count for the second consecutive time."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Question:** *Which new sport was introduced at the 2024 Olympics?*"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**BERT's Extracted Answer:** **breakdancing**"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Confidence Score:** 0.9941"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "---"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### 2. Named Entity Recognition (NER)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Input Text:** Angela Merkel met with the CEO of Siemens in Berlin yesterday."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Identified Entities:**"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* **Entity:** **Angela Merkel** (Type: `PER`, Score: 0.9930)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* **Entity:** **Siemens** (Type: `ORG`, Score: 0.9987)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* **Entity:** **Berlin** (Type: `LOC`, Score: 0.9996)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "---"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### 3. Feature Extraction (Sentence Embeddings)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Input Text:** 'BERT is a powerful language model.'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Sentence Embedding Shape (Vector Size):** torch.Size([1, 768])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**First 5 dimensions of the 768-dim vector:**"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4806293  -0.2720138   0.07131609 -0.16561534 -0.5366288 ]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZknMovKOPMaN"
   },
   "source": [
    "## Language Translation with T5\n",
    "Let’s translate a sentence using the T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53rW5o2KPMaN",
    "outputId": "901b28b8-2dea-47b2-bbce-6162b352a268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/ianmcculloh/myenvGL/lib/python3.9/site-packages (0.2.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianmcculloh/myenvGL/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Le temps est ensoleillé.\n"
     ]
    }
   ],
   "source": [
    "# uinstall necessary libraries\n",
    "!pip install sentencepiece\n",
    "\n",
    "#load libraries\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load pre-trained T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Input text for translation\n",
    "input_text = \"translate English to French: The weather is sunny.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate translation\n",
    "output = model.generate(inputs.input_ids, max_length=50)\n",
    "\n",
    "# Decode the generated translation\n",
    "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Translation:\", translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ANXTFVEPMaN"
   },
   "source": [
    "Let's use T5 for text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSWZ08iiPMaN",
    "outputId": "4518a401-b41b-4284-bea0-a72a08098262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the painting is considered an archetypal masterpiece of the italian Renaissance. it has been described as the most famous, most visited, most written about, and most sung about work of art.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the pre-trained T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")  # \"t5-small\" is a smaller, faster version of T5\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Input text for summarization\n",
    "text = \"\"\"\n",
    "The Mona Lisa is a half-length portrait painting by the Italian artist Leonardo da Vinci.\n",
    "It is considered an archetypal masterpiece of the Italian Renaissance, and it has been described\n",
    "as the most famous, most visited, most written about, and most sung about work of art in the world.\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the text for the T5 model\n",
    "# T5 treats all tasks as text-to-text; for summarization, we prepend \"summarize: \" to the input text\n",
    "input_text = \"summarize: \" + text\n",
    "\n",
    "# Tokenize the input text and convert it to a PyTorch tensor\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(\n",
    "    inputs,\n",
    "    max_length=50,          # Maximum length of the summary\n",
    "    num_beams=4,            # Beam search with 4 beams for more coherent output\n",
    "    early_stopping=True     # Stop once an optimal summary is found\n",
    ")\n",
    "\n",
    "# Decode the generated summary back to text\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated summary\n",
    "print(\"Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvGL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
